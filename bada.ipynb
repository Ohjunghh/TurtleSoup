{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5e0b2df8-4be7-4158-8cf8-7197afc4f68d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7912\n",
      "* Running on public URL: https://4aa61e158720c69626.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4aa61e158720c69626.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import ollama\n",
    "from scenarios import scenarios,MAX_QUESTIONS,MAX_HINTS,tutorial_questions\n",
    "\n",
    "def get_empty_state():\n",
    "    return {\"question_history\": [], \"used_answer\": False, \"hint_count\": 0, \"tutorial_step\": 0}\n",
    "\n",
    "scenario_states = [get_empty_state() for _ in scenarios]\n",
    "\n",
    "def reset_game(idx):\n",
    "    scenario_states[idx] = get_empty_state()\n",
    "    return [], \"\", MAX_QUESTIONS, MAX_HINTS, idx\n",
    "\n",
    "def handle_question(user_question, user_answer, request_hint, history, idx):\n",
    "    state = scenario_states[idx]\n",
    "    scenario = scenarios[idx][\"scenario\"]\n",
    "    truth = scenarios[idx][\"truth\"]\n",
    "\n",
    "    if state[\"used_answer\"]:\n",
    "        if request_hint:\n",
    "            history.append({\"role\": \"user\", \"content\": \"💡 힌트 요청\"})\n",
    "            history.append({\"role\": \"assistant\", \"content\": \"이미 정답을 제출했습니다. 게임이 종료되었습니다. 홈으로 돌아가 새 시나리오를 선택하세요.\"})\n",
    "        elif user_question.strip():\n",
    "            history.append({\"role\": \"user\", \"content\": user_question})\n",
    "            history.append({\"role\": \"assistant\", \"content\": \"이미 정답을 제출했습니다. 게임이 종료되었습니다. 홈으로 돌아가 새 시나리오를 선택하세요.\"})\n",
    "        elif user_answer.strip():\n",
    "            history.append({\"role\": \"user\", \"content\": f\"✅ 정답 제출: {user_answer}\"})\n",
    "            history.append({\"role\": \"assistant\", \"content\": \"이미 정답을 제출했습니다. 게임이 종료되었습니다. 홈으로 돌아가 새 시나리오를 선택하세요.\"})\n",
    "        return history, \"\", 0, MAX_HINTS - state[\"hint_count\"], idx,\"\"\n",
    "\n",
    "    # 튜토리얼\n",
    "    if idx == 0 and not user_answer and not request_hint:\n",
    "        step = state.get(\"tutorial_step\", 0)\n",
    "        \n",
    "        if step < len(tutorial_questions) and user_question.strip() == tutorial_questions[step]:\n",
    "            # 사용자 질문 & 응답 추가\n",
    "            history.append({\"role\": \"user\", \"content\": user_question})\n",
    "            history.append({\"role\": \"assistant\", \"content\": \"예\"})\n",
    "            state[\"tutorial_step\"] = step + 1\n",
    "            \n",
    "            # 다음 튜토리얼 안내 메시지 (새로운 말풍선으로)\n",
    "            if state[\"tutorial_step\"] < len(tutorial_questions):\n",
    "                next_q = tutorial_questions[state[\"tutorial_step\"]]\n",
    "                history.append({\"role\": \"assistant\", \"content\": \n",
    "                    f\"\\n\\n이렇게 질문해 보세요!\\n{state['tutorial_step']+1}️⃣ {next_q}\"})\n",
    "            else:\n",
    "                history.append({\"role\": \"assistant\", \"content\": \n",
    "                    \"\\n\\n 이제 정답에 가까워진 것 같습니다!\\n\\n 정답을 입력해보세요.\\n남자는 진짜 바다거북스프를 먹고 전에 먹은 것이 시체로 끓인 스프란 것을 깨닫고 목숨을 끊었다.\"})\n",
    "            \n",
    "            state[\"question_history\"].append(user_question)\n",
    "            return history, \"\", MAX_QUESTIONS - len(state[\"question_history\"]), MAX_HINTS - state[\"hint_count\"], idx,\"\"\n",
    "            \n",
    "    # 힌트 요청 처리\n",
    "    if request_hint:\n",
    "        if state[\"hint_count\"] >= MAX_HINTS:\n",
    "            history.append({\"role\": \"user\", \"content\": \"💡 힌트 요청\"})  # 사용자 메시지\n",
    "            history.append({\"role\": \"assistant\", \"content\": \"힌트 기회를 모두 사용했습니다.\"})  # 어시스턴트 메시지\n",
    "            return history, \"\", MAX_QUESTIONS - len(state[\"question_history\"]), MAX_HINTS - state[\"hint_count\"], idx,\"\"\n",
    "            #return history, \"힌트 기회를 모두 사용했습니다.\", MAX_QUESTIONS - len(state[\"question_history\"]), MAX_HINTS - state[\"hint_count\"], idx\n",
    "\n",
    "        hint_prompt = (\n",
    "            \"너는 반드시 아래 시나리오와 정답만을 참고해서, 정답을 직접적으로 노출하지 않으면서도 사용자가 진실에 가까워지도록 돕는 의미 있는 단서를 한 문장으로 생성하는 역할이야.\\n\"\n",
    "            \"### 힌트 생성 원칙 ###\\n\"\n",
    "            \"다른 시나리오나 외부 정보는 절대 참고하지 마.\\n\"\n",
    "            \"힌트는 너무 추상적이거나 전혀 관련 없는 내용이 아니어야 하며, 반드시 시나리오의 맥락과 연결되어야 해.\\n\"\n",
    "            \"정답의 핵심 이유는 직접 언급하지 말고, 주변 맥락이나 물리적 조건, 상황적 제약 등만 암시해.\\n\"\n",
    "            \"### 출력 원칙 ###\\n\"\n",
    "            \"힌트는 한 문장으로만 작성하고 반드시 그 한문장만 출력해. 그 외의 설명은 덧붙이지마. 접두사도 붙이지마.\"\n",
    "        )\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": hint_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"시나리오: {scenario}\\n정답: {truth}\"}\n",
    "        ]\n",
    "        res = ollama.chat(model=\"EEVE-korean-10.8B\", messages=messages)\n",
    "        state[\"hint_count\"] += 1\n",
    "\n",
    "         # 힌트 메시지 추가 방식 변경\n",
    "        history.append({\"role\": \"user\", \"content\": \"💡 힌트 요청\"})  # 사용자 메시지\n",
    "        history.append({\"role\": \"assistant\", \"content\": f\"💡 힌트: {res['message']['content'].strip()}\"})  # 어시스턴트 메시지\n",
    "\n",
    "        return history, \"\", MAX_QUESTIONS - len(state[\"question_history\"]), MAX_HINTS - state[\"hint_count\"], idx,\"\"\n",
    "       \n",
    "    # 정답 제출 처리\n",
    "    if user_answer:\n",
    "        if state[\"used_answer\"]:\n",
    "            return history, \"⚠️ 이미 정답을 제출했습니다. 게임이 종료되었습니다.\", 0, MAX_HINTS - state[\"hint_count\"], idx,\"\"\n",
    "\n",
    "        state[\"used_answer\"] = True\n",
    "        judge_prompt = (\n",
    "            \"너는 사용자가 제출한 정답과 실제 정답이 '의미적으로 동일한지' 판단하는 역할이야.  \"\n",
    "            \"'핵심 원인(왜 그런 일이 벌어졌는가)'만 비교하고, 세부적 표현은 무시해야해.  \"\n",
    "            \" 다만, 사용자의 답변이 문제 상황과 명백히 무관하거나, 정답과 관련된 '의미 있는 원인'이 포함되지 않았다면 오답으로 판단해야 해. \"\n",
    "            \n",
    "            \"### 판단 기준 (반드시 준수)###  \"\n",
    "            \"1. 정답 조건: 제출된 답변의 '사건 발생 이유'가 실제 정답과 본질적으로 같거나 유사할 때 \"\n",
    "            \"2. 오답 조건: 사건의 원인이 다르거나, 핵심 사실이 누락되었을 때  \"\n",
    "            \"3. 절대적 원칙: 시간 순서, 표현 방식, 수식어는 '전혀 고려하지 않음' \"\n",
    "            \"   '동의어나 추상적 표현'도 같은 의미면 정답  \"\n",
    "            \"단, 핵심 원인 자체가 빠지거나 의미 없는 내용일 경우 반드시 '오답' \"\n",
    "            \"특히, '사과', '모른다', '죄송', '미안', '아무 말도 아닌 말장난' 등은 무조건 오답으로 처리해야 해.\\n\"\n",
    "            \n",
    "            \"### 출력 원칙###  \"\n",
    "            \" 반드시 '정답' 또는 '오답' 중 1개만 출력.\"\n",
    "            \" 그 외 어떤 설명도 절대 추가하면 안됩니다.\"\n",
    "        )\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": judge_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"정답: {truth.strip()}\\n제출된 정답: {user_answer.strip()}\"}\n",
    "        ]\n",
    "        res = ollama.chat(model=\"EEVE-korean-10.8B\", messages=messages)\n",
    "        result = res[\"message\"][\"content\"].strip()\n",
    "\n",
    "        history.append({\"role\": \"user\", \"content\": f\"✅ 정답 제출: {user_answer}\"})\n",
    "\n",
    "        if \"정답\" in result:\n",
    "            history.append({\"role\": \"assistant\", \"content\": f\"정답입니다!\\n{truth.strip()}\"})\n",
    "        else:\n",
    "            history.append({\"role\": \"assistant\", \"content\": f\"틀렸습니다. 정답은 다음과 같습니다:\\n{truth.strip()}\"})\n",
    "\n",
    "        return history, \"\", 0, MAX_HINTS - state[\"hint_count\"], idx,\"\"\n",
    "\n",
    "    if not user_question.strip() and not user_answer.strip() and not request_hint:\n",
    "    # 아무 입력도 없으면 그대로 반환 (질문 입력란도 비움)\n",
    "        return history, \"\", MAX_QUESTIONS - len(state[\"question_history\"]), MAX_HINTS - state[\"hint_count\"], idx, \"\"\n",
    "    \n",
    "    # 질문 횟수 체크\n",
    "    if len(state[\"question_history\"]) >= MAX_QUESTIONS:\n",
    "        #return history, \"질문 횟수를 모두 소진했습니다. 정답을 제출해보세요.\", 0, MAX_HINTS - state[\"hint_count\"], idx\n",
    "        if user_question.strip():\n",
    "            history.append({\"role\": \"user\", \"content\": user_question})\n",
    "            history.append({\"role\": \"assistant\", \"content\": \"질문 횟수를 모두 소진했습니다. 정답을 제출해보세요.\"})\n",
    "        return history, \"\", 0, MAX_HINTS - state[\"hint_count\"], idx,\"\"\n",
    "        \n",
    "    # 일반 질문 처리\n",
    "    qa_prompt = (\n",
    "        \"너는 추리 게임의 출제자이다. 사용자가 시나리오의 진실(정답)을 추리할 수 있도록 '예', '아니오', '예/아니오로 대답할 수 없음', '추리랑 관련된 질문이 아닙니다' 중 하나로만 답해야 한다.\\n\"\n",
    "\n",
    "        \"### 판단 기준 (반드시 준수)###  \"\n",
    "        \"1. 사용자의 질문이 정답(진실)을 구성하는 핵심 사실(예: '아이의 키가 작다', '엘리베이터 버튼을 손으로 못 누른다') 중 1개 이상과 의미적으로 같거나, 사실상 같은 내용을 묻는다면 반드시 '예'로 답해.\\n\"\n",
    "        \"   - 질문 어투, 말투, 단어, 높임말, 순서, 조사, 어순, 어는 무시하고 오직 의미 중심으로 판단해.\\n\"\n",
    "        \"   - 예시: '아이의 키가 작나요?', '아이의 키가 작아 ?', '애의 키가 작지?','아이 키가 작죠?' 모두 같은 의미\\n\"\n",
    "        \"   - 또한, 정답을 구성하는 핵심 사실과의 직접적인 의미 연관성을 묻는 질문(예: '정답이 아이의 키랑 관련있나요?')에서도, 관련이 있다고 파악되면 '예'로 답해.\"\n",
    "        \n",
    "        \"2. 사용자의 질문이 정답을 구성하는 핵심 사실과 명백히 무관하거나, 반대 의미거나 틀린 해석이면 '아니오'로 답해.\\n\"\n",
    "        \"   - 핵심 사실과 관련 없어 보이는 주변 정보만 묻는 질문도 '아니오'\\n\"\n",
    "        \n",
    "        \"3. 왜', '어떻게'와 같이 예/아니오로 명확히 답할 수 없는 질문(예: '왜 그런 일이 일어났나요?')만 '예/아니오로 대답할 수 없음'으로 답해.\\n\"\n",
    "        \n",
    "        \"4. 질문이 게임 진행과 전혀 관련 없으면 '추리랑 관련된 질문이 아닙니다.'로 답해.\\n\"\n",
    "        \"- 일상/잡담/명령 (예: '오늘 날씨 어때?','메뉴 추천 좀','힌트 줘')\"\n",
    "        \"- 감탄사/의성어/말장난/무의미한 표현 : (예: '음','...','아아','와','유유','야야','ㅇ?','ㅇㅇ')\"\n",
    "        \"- 정답을 무작정 요구하는 질문(예:'정답이 뭐야?','정답은?','정답 알려줘','답 내놔','정답을 알려줄 수 있나요?')\"\n",
    "\n",
    "        \"### 출력 원칙###\\n\"\n",
    "        \"- 반드시 아래 네 가지 중 하나만 출력해야 한다:\\n\"\n",
    "        \"  '예', '아니오', '예/아니오로 대답할 수 없음', '추리랑 관련된 질문이 아닙니다'\\n\"\n",
    "        \"- 그 외에 추가 설명, 부연 설명, 이유는 금지한다.\\n\"\n",
    "        \"- 오직 지정해놓은 것 중 하나만 출력: '예' / '아니오' / '예/아니오로 대답할 수 없음' / '추리랑 관련된 질문이 아닙니다'\\n\"\n",
    "    )\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": qa_prompt},\n",
    "        {\"role\": \"user\", \"content\": (\n",
    "            f\"[시나리오]\\n{scenario.strip()}\\n\\n\"\n",
    "            f\"[정답]\\n{truth.strip()}\\n\\n\"\n",
    "            f\"[지금까지 질문 목록]\\n\"\n",
    "            + (\"\\n\".join([f\"Q: {msg['content']}\" for msg in history if msg['role'] == 'user']) if history else \"없음\")\n",
    "            + f\"\\n\\n[새 질문]\\n{user_question.strip()}\\n\"\n",
    "        )}\n",
    "    ]\n",
    "    res = ollama.chat(model=\"EEVE-korean-10.8B\", messages=messages)\n",
    "    response = res['message']['content'].strip()\n",
    "\n",
    "    for prefix in [\"답변:\", \"A:\", \"Q:\", \"정답:\", \"오답:\", \"답:\", \"답 :\"]:\n",
    "        if response.startswith(prefix):\n",
    "            response = response[len(prefix):].strip()\n",
    "\n",
    "    state[\"question_history\"].append(user_question)\n",
    "    history.append({\"role\": \"user\", \"content\": user_question})\n",
    "    history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    return history, \"\", MAX_QUESTIONS - len(state[\"question_history\"]), MAX_HINTS - state[\"hint_count\"], idx, \"\"\n",
    "\n",
    "with gr.Blocks(css=\"\"\"\n",
    ".gradio-container {\n",
    "    background: url('/gradio_api/file=img/beach.png') no-repeat center center fixed;\n",
    "    background-size: cover;\n",
    "    min-height: 100vh;\n",
    "}\n",
    "#center_wrap {\n",
    "    display: flex;\n",
    "    justify-content: center;\n",
    "    align-items: center;\n",
    "    height: 100vh;\n",
    "}\n",
    "#scenario-title {\n",
    "    display: flex;\n",
    "    flex-direction: column;\n",
    "    gap: 24px;\n",
    "    margin-top: 20px;\n",
    "    align-items: center;\n",
    "    min-width: 400px;\n",
    "    max-width: 600px; \n",
    "}\n",
    "#main_col {\n",
    "    min-width: 400px;\n",
    "    max-width: 600px;\n",
    "    margin: auto;\n",
    "    align-items: center;\n",
    "    background: #f2f2f2;           /* 연한 회색 배경 */\n",
    "    border-radius: 18px;           /* 둥근 모서리 */\n",
    "    box-shadow: 0 4px 16px rgba(0,0,0,0.08); /* 그림자 */\n",
    "    padding: 32px 24px 24px 24px;  /* 내부 여백 */\n",
    "}\n",
    "\"\"\") as demo:\n",
    "    scenario_idx_state = gr.State(0)\n",
    "    # --- 시나리오 선택 화면 ---\n",
    "    with gr.Column(visible=True) as home_page:\n",
    "        with gr.Row():\n",
    "            gr.Column(scale=1)  # 왼쪽 여백\n",
    "            with gr.Column(scale=2, elem_id=\"main_col\"):  # 중앙 컨텐츠 (최대 600px)\n",
    "                gr.Markdown(\"## 🐢 시나리오를 선택하세요!\",elem_id=\"scenario-title\")\n",
    "                scenario_btns = []\n",
    "                for idx, s in enumerate(scenarios):\n",
    "                    btn = gr.Button(s[\"title\"])\n",
    "                    scenario_btns.append(btn)\n",
    "            gr.Column(scale=1)  # 오른쪽 여백\n",
    "    \n",
    "   # --- 챗 봇 화면 ---\n",
    "    with gr.Column(visible=False) as game_page:\n",
    "        # 전체 행 구조\n",
    "        with gr.Row():\n",
    "            # 왼쪽 여백 (scale=1)\n",
    "            gr.Column(scale=1)\n",
    "            \n",
    "            # 메인 컨텐츠 영역 (scale=2)\n",
    "            with gr.Column(scale=2, min_width=500, elem_id=\"main_col\"):\n",
    "                # 질문 수/힌트 수 행\n",
    "                with gr.Row():\n",
    "                    remaining_text = gr.Textbox(label=\"남은 질문 수\", interactive=False)\n",
    "                    hint_text = gr.Textbox(label=\"남은 힌트 수\", interactive=False)\n",
    "                    \n",
    "                # 챗봇 영역\n",
    "                gr.Markdown(\"## 🐢 바다거북 수프 추리 게임\")\n",
    "                chatbox = gr.Chatbot(type=\"messages\", layout=\"bubble\", height=500)\n",
    "                question_input = gr.Textbox(label=\"👉 질문을 입력해주세요\")\n",
    "                answer_input = gr.Textbox(label=\"✅ 정답 제출 (1회만)\")\n",
    "                \n",
    "                # 버튼 행\n",
    "                with gr.Row():\n",
    "                    submit_btn = gr.Button(\"🎯 질문 / 정답 제출\")\n",
    "                    hint_btn = gr.Button(\"💡 힌트 요청\")\n",
    "                    home_btn = gr.Button(\"🏠 홈으로 가기\")\n",
    "            \n",
    "            # 오른쪽 여백 (scale=1)\n",
    "            gr.Column(scale=1)\n",
    "\n",
    "            \n",
    "    # --- 이벤트 핸들링 ---\n",
    "    def show_game_ui(idx):\n",
    "        scenario_states[idx] = get_empty_state()\n",
    "        scenario_text = scenarios[idx][\"scenario\"].strip()\n",
    "        history = [{\"role\": \"assistant\", \"content\": scenario_text}]\n",
    "         # 튜토리얼이면 첫 안내 추가\n",
    "        if idx == 0:\n",
    "            first_q = tutorial_questions[0]\n",
    "            history.append({\"role\": \"assistant\", \"content\": f\"\\n\\n이렇게 질문해 보세요! 1️⃣ {first_q}\"})\n",
    "            scenario_states[idx][\"tutorial_step\"] = 0\n",
    "        return (\n",
    "            gr.update(visible=False),\n",
    "            gr.update(visible=True),\n",
    "            history, \"\", MAX_QUESTIONS, MAX_HINTS, idx,\"\")\n",
    "\n",
    "    def go_home(idx):\n",
    "        return (\n",
    "            gr.update(visible=True),\n",
    "            gr.update(visible=False),\n",
    "            [], \"\", MAX_QUESTIONS, MAX_HINTS, 0,\"\")\n",
    "\n",
    "    for idx, btn in enumerate(scenario_btns):\n",
    "        btn.click(\n",
    "            lambda idx=idx: show_game_ui(idx),\n",
    "            inputs=None, \n",
    "            outputs=[home_page, game_page, chatbox, answer_input, remaining_text, hint_text, scenario_idx_state, question_input])\n",
    "\n",
    "    # 홈 버튼 클릭\n",
    "    home_btn.click(go_home, inputs=[scenario_idx_state], outputs=[home_page, game_page, chatbox, answer_input, remaining_text, hint_text, scenario_idx_state,question_input])\n",
    "    \n",
    "    # 질문/정답 제출 버튼 클릭\n",
    "    submit_btn.click(handle_question, [question_input, answer_input, gr.State(False), chatbox, scenario_idx_state], [chatbox, answer_input, remaining_text, hint_text, scenario_idx_state,question_input])\n",
    "    \n",
    "    # 질문 입력칸에서 엔터\n",
    "    question_input.submit(handle_question, [question_input, answer_input, gr.State(False), chatbox, scenario_idx_state], [chatbox, answer_input, remaining_text, hint_text, scenario_idx_state, question_input])\n",
    "    \n",
    "    # 정답 입력칸에서 엔터\n",
    "    answer_input.submit(handle_question, [question_input, answer_input, gr.State(False), chatbox, scenario_idx_state], [chatbox, answer_input, remaining_text, hint_text, scenario_idx_state,question_input])\n",
    "    \n",
    "    # 힌트 버튼\n",
    "    hint_btn.click(lambda chatbox, idx: handle_question(\"\", \"\", True, chatbox, idx), [chatbox, scenario_idx_state], [chatbox, answer_input, remaining_text, hint_text, scenario_idx_state,question_input])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True,allowed_paths=[\"img\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f384167f-b76c-4306-8bb6-ada4c8847799",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.4.8-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.0.0)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.8.0 (from gradio)\n",
      "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /root/.local/lib/python3.10/site-packages (from gradio) (0.30.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.24.1)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
      "Collecting pandas<3.0,>=1.0 (from gradio)\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.3.0)\n",
      "Collecting pydantic<2.12,>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.4.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in /root/.local/lib/python3.10/site-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.8.0->gradio)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.1.3)\n",
      "Collecting typing-extensions~=4.0 (from gradio)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2022.12.7)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Downloading httpcore-1.0.8-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/.local/lib/python3.10/site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Downloading pydantic_core-2.33.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<2.12,>=2.0->gradio)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting click>=8.0.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (1.26.13)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ollama-0.4.8-py3-none-any.whl (13 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.8-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m266.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.6/443.6 kB\u001b[0m \u001b[31m170.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.33.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m263.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m169.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m146.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, pydub, websockets, tzdata, typing-extensions, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, mdurl, h11, groovy, ffmpy, click, annotated-types, aiofiles, uvicorn, typing-inspection, starlette, pydantic-core, pandas, markdown-it-py, httpcore, rich, pydantic, httpx, typer, safehttpx, ollama, gradio-client, fastapi, gradio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "Successfully installed aiofiles-24.1.0 annotated-types-0.7.0 click-8.1.8 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 h11-0.14.0 httpcore-1.0.8 httpx-0.28.1 markdown-it-py-3.0.0 mdurl-0.1.2 ollama-0.4.8 orjson-3.10.16 pandas-2.2.3 pydantic-2.11.3 pydantic-core-2.33.1 pydub-0.25.1 python-multipart-0.0.20 pytz-2025.2 rich-14.0.0 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.46.2 tomlkit-0.13.2 typer-0.15.2 typing-extensions-4.13.2 typing-inspection-0.4.0 tzdata-2025.2 uvicorn-0.34.2 websockets-15.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee695dd-cc74-46bd-a0f8-3a3db43357e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
